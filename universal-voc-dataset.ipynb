{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ccbc1f",
   "metadata": {},
   "source": [
    "# Universal Perturbation on The PASCAL Visual Object Classes Challenge 2012 (VGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb04ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torchvision torch sklearn pandas gdown \n",
    "!conda install -y -c conda-forge ipywidgets tqdm widgetsnbextension\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac852c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ccb588",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac82411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, output_dim, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.features = features\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.to(self.device)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        return x, h\n",
    "    \n",
    "vgg11_config = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "\n",
    "vgg13_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512,\n",
    "                512, 'M']\n",
    "\n",
    "vgg16_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512,\n",
    "                'M', 512, 512, 512, 'M']\n",
    "\n",
    "vgg19_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512,\n",
    "                512, 512, 'M', 512, 512, 512, 512, 'M']\n",
    "    \n",
    "def get_vgg_layers(config, batch_norm):\n",
    "\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "\n",
    "    for c in config:\n",
    "        assert c == 'M' or isinstance(c, int)\n",
    "        if c == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, c, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(c), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = c\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "vgg11_layers = get_vgg_layers(vgg11_config, batch_norm=True)\n",
    "vgg11_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c7c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 20\n",
    "\n",
    "model = VGG(vgg11_layers, OUTPUT_DIM, 'cuda')\n",
    "# for freeze weight\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88fa133",
   "metadata": {},
   "source": [
    "## Load pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd37b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "pretrained_model = models.vgg11_bn(pretrained=True)\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d20dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.classifier[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f34416",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_FEATURES = pretrained_model.classifier[-1].in_features\n",
    "\n",
    "final_fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
    "pretrained_model.classifier[-1] = final_fc\n",
    "pretrained_model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1750eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(pretrained_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab3a539",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff2921",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'VOC2012'\n",
    "ROOT_test = ROOT + \"_test\"\n",
    "\n",
    "if not os.path.isdir(ROOT):\n",
    "    !wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar -O /tmp/VOC.tar\n",
    "    !tar -xvf /tmp/VOC.tar\n",
    "    !mv VOCdevkit/VOC2012 VOC2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39866e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(ROOT_test):\n",
    "    !gdown --id 1gVllQTZdxA82byaZ_SjeOyjns0qnugwR -O /tmp/VOC_test.tar\n",
    "    !tar -xvf /tmp/VOC_test.tar\n",
    "    !mv VOCdevkit/VOC2012 VOC2012_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9103ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_size = 224\n",
    "pretrained_means = [0.485, 0.456, 0.406]\n",
    "pretrained_stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.RandomRotation(5),\n",
    "                           transforms.RandomHorizontalFlip(0.5),\n",
    "                           transforms.RandomCrop(pretrained_size, padding=10),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=pretrained_means,\n",
    "                                                std=pretrained_stds)\n",
    "                       ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.CenterCrop(pretrained_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=pretrained_means,\n",
    "                                                std=pretrained_stds)\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904f0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "def load_dataset(c):\n",
    "    df = pd.read_csv(f\"{ROOT}/ImageSets/Main/{c}_trainval.txt\", delimiter=r\"\\s+\", header=None, names=('id', c))\n",
    "    return df\n",
    "\n",
    "classes = ['bicycle', 'horse', 'cat', 'dog', 'pottedplant', 'aeroplane', 'sofa', 'bus', 'car', 'chair', 'bird', 'boat', 'cow', 'bottle', 'diningtable', 'person', 'tvmonitor', 'sheep', 'motorbike', 'train']\n",
    "df = reduce(lambda df1,df2: pd.merge(df1,df2,on='id'), [load_dataset(c) for c in classes])\n",
    "df['label'] = df.apply(lambda row: row[classes].tolist().index(1), axis=1)\n",
    "\n",
    "with open(f\"{ROOT}/ImageSets/Main/train.txt\", 'r') as f:\n",
    "    _ = f.read().split('\\n')\n",
    "    df['train'] = df.apply(lambda row: row.values[0] in _, axis=1)\n",
    "train_data_df = df[df['train']][['id','label']]\n",
    "valid_data_df = df[df['train'] == False][['id','label']]\n",
    "\n",
    "print(len(train_data_df))\n",
    "print(len(valid_data_df))\n",
    "train_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5081d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_test(c):\n",
    "    df = pd.read_csv(f\"{ROOT_test}/ImageSets/Main/{c}_test.txt\", delimiter=r\"\\s+\", header=None, names=('id', c))\n",
    "    return df\n",
    "\n",
    "df_test = reduce(lambda df1,df2: pd.merge(df1,df2,on='id'), [load_dataset_test(c) for c in classes])\n",
    "df_test['label'] = np.zeros(len(df_test), dtype=int)\n",
    "\n",
    "test_data_df = df_test[['id', 'label']]\n",
    "test_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.labels = data['label'].tolist()\n",
    "        self.image_paths = data['id'].tolist()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = f\"{ROOT}/JPEGImages/{self.data.iloc[idx].values[0]}.jpg\"\n",
    "        image = Image.open(image_filepath)\n",
    "        \n",
    "        label = self.data.iloc[idx].values[1]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "train_data = VOCDataset(train_data_df, train_transforms)\n",
    "valid_data = VOCDataset(valid_data_df, test_transforms)\n",
    "test_data  = VOCDataset(test_data_df, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f96395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min=image_min, max=image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image\n",
    "\n",
    "\n",
    "def plot_images(images, labels, classes, normalize=True):\n",
    "\n",
    "    n_images = len(images)\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "\n",
    "        image = images[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        ax.set_title(classes[labels[i]])\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMAGES = 25\n",
    "\n",
    "images, labels = zip(*[(image, label) for image, label in\n",
    "                       [train_data[i] for i in range(N_IMAGES)]])\n",
    "\n",
    "plot_images(images, labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9d839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator = data.DataLoader(train_data,\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(valid_data,\n",
    "                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "test_iterator = data.DataLoader(test_data,\n",
    "                                batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736df6ab",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45630cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_LR = 1e-7\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=START_LR)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model.features\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.classifier = model.classifier.to(device)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cccd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class LRFinder:\n",
    "    def __init__(self, model, optimizer, criterion, device):\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "\n",
    "        torch.save(model.state_dict(), 'init_params.pt')\n",
    "\n",
    "    def range_test(self, iterator, end_lr=10, num_iter=100,\n",
    "                   smooth_f=0.05, diverge_th=5):\n",
    "\n",
    "        lrs = []\n",
    "        losses = []\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        lr_scheduler = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
    "\n",
    "        iterator = IteratorWrapper(iterator)\n",
    "\n",
    "        for iteration in tqdm(range(num_iter)):\n",
    "\n",
    "            loss = self._train_batch(iterator)\n",
    "\n",
    "            lrs.append(lr_scheduler.get_last_lr()[0])\n",
    "\n",
    "            # update lr\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            if iteration > 0:\n",
    "                loss = smooth_f * loss + (1 - smooth_f) * losses[-1]\n",
    "\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "\n",
    "            losses.append(loss)\n",
    "\n",
    "            if loss > diverge_th * best_loss:\n",
    "                print(\"Stopping early, the loss has diverged\")\n",
    "                break\n",
    "\n",
    "        # reset model to initial parameters\n",
    "        model.load_state_dict(torch.load('init_params.pt'))\n",
    "\n",
    "        return lrs, losses\n",
    "\n",
    "    def _train_batch(self, iterator):\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        x, y = iterator.get_batch()\n",
    "\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "\n",
    "        y_pred, _ = self.model(x)\n",
    "\n",
    "        loss = self.criterion(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "\n",
    "class ExponentialLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
    "        self.end_lr = end_lr\n",
    "        self.num_iter = num_iter\n",
    "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        curr_iter = self.last_epoch\n",
    "        r = curr_iter / self.num_iter\n",
    "        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in\n",
    "                self.base_lrs]\n",
    "\n",
    "\n",
    "class IteratorWrapper:\n",
    "    def __init__(self, iterator):\n",
    "        self.iterator = iterator\n",
    "        self._iterator = iter(iterator)\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            inputs, labels = next(self._iterator)\n",
    "        except StopIteration:\n",
    "            self._iterator = iter(self.iterator)\n",
    "            inputs, labels, *_ = next(self._iterator)\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def get_batch(self):\n",
    "        return next(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39c0f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "END_LR = 10\n",
    "NUM_ITER = 100\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device)\n",
    "lrs, losses = lr_finder.range_test(train_iterator, END_LR, NUM_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a613ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_finder(lrs, losses, skip_start=5, skip_end=5):\n",
    "\n",
    "    if skip_end == 0:\n",
    "        lrs = lrs[skip_start:]\n",
    "        losses = losses[skip_start:]\n",
    "    else:\n",
    "        lrs = lrs[skip_start:-skip_end]\n",
    "        losses = losses[skip_start:-skip_end]\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(lrs, losses)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Learning rate')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.grid(True, 'both', 'x')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ddefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lr_finder(lrs, losses, skip_start=10, skip_end=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e3f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOUND_LR = 5e-5\n",
    "\n",
    "params = [\n",
    "          {'params': model.features.parameters(), 'lr': FOUND_LR / 10},\n",
    "          {'params': model.classifier.parameters()}\n",
    "         ]\n",
    "\n",
    "optimizer = optim.Adam(params, lr=FOUND_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f9b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred, _ = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6007571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82321b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40836c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "\n",
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "universal",
   "language": "python",
   "name": "universal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
