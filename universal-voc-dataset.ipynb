{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ccbc1f",
   "metadata": {},
   "source": [
    "# Universal Perturbation on The PASCAL Visual Object Classes Challenge 2012 (VGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb04ba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in ./universal/lib/python3.8/site-packages (0.12.0)\n",
      "Requirement already satisfied: torch in ./universal/lib/python3.8/site-packages (1.11.0)\n",
      "Requirement already satisfied: sklearn in ./universal/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: pandas in ./universal/lib/python3.8/site-packages (1.4.2)\n",
      "Collecting gdown\n",
      "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./universal/lib/python3.8/site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: numpy in ./universal/lib/python3.8/site-packages (from torchvision) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions in ./universal/lib/python3.8/site-packages (from torchvision) (4.1.1)\n",
      "Requirement already satisfied: requests in ./universal/lib/python3.8/site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: scikit-learn in ./universal/lib/python3.8/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./universal/lib/python3.8/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./universal/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tqdm in ./universal/lib/python3.8/site-packages (from gdown) (4.64.0)\n",
      "Requirement already satisfied: beautifulsoup4 in ./universal/lib/python3.8/site-packages (from gdown) (4.11.1)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: six in ./universal/lib/python3.8/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./universal/lib/python3.8/site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in ./universal/lib/python3.8/site-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in ./universal/lib/python3.8/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./universal/lib/python3.8/site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./universal/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./universal/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./universal/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./universal/lib/python3.8/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14775 sha256=002b68d35a5f41efd60180f877dc6443fffe434e639e2d555da4a97a2ca3f7b5\n",
      "  Stored in directory: /home/waris/.cache/pip/wheels/7b/7b/5d/656f46cd6889e4c93977be9586901d0adc1271b2d876c84c96\n",
      "Successfully built gdown\n",
      "Installing collected packages: filelock, gdown\n",
      "Successfully installed filelock-3.6.0 gdown-4.4.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/waris/Projects/universal/universal/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torchvision torch sklearn pandas gdown \n",
    "!conda install -y -c conda-forge ipywidgets tqdm widgetsnbextension\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac852c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ccb588",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac82411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, output_dim, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.features = features\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.to(self.device)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        return x, h\n",
    "    \n",
    "vgg11_config = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "\n",
    "vgg13_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512,\n",
    "                512, 'M']\n",
    "\n",
    "vgg16_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512,\n",
    "                'M', 512, 512, 512, 'M']\n",
    "\n",
    "vgg19_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512,\n",
    "                512, 512, 'M', 512, 512, 512, 512, 'M']\n",
    "    \n",
    "def get_vgg_layers(config, batch_norm):\n",
    "\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "\n",
    "    for c in config:\n",
    "        assert c == 'M' or isinstance(c, int)\n",
    "        if c == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, c, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(c), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = c\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "vgg11_layers = get_vgg_layers(vgg11_config, batch_norm=True)\n",
    "vgg11_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c7c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 20\n",
    "\n",
    "model = VGG(vgg11_layers, OUTPUT_DIM, 'cuda')\n",
    "# for freeze weight\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad78e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88fa133",
   "metadata": {},
   "source": [
    "## Load pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd37b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "pretrained_model = models.vgg11_bn(pretrained=True)\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d20dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.classifier[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f34416",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_FEATURES = pretrained_model.classifier[-1].in_features\n",
    "\n",
    "final_fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
    "pretrained_model.classifier[-1] = final_fc\n",
    "pretrained_model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1750eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(pretrained_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab3a539",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11ff2921",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'VOC2012'\n",
    "ROOT_test = ROOT + \"_test\"\n",
    "\n",
    "if not os.path.isdir(ROOT):\n",
    "    !wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar -O /tmp/VOC.tar\n",
    "    !tar -xvf /tmp/VOC.tar\n",
    "    !mv VOCdevkit/VOC2012 VOC2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2456c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(ROOT_test):\n",
    "    !gdown --id 1gVllQTZdxA82byaZ_SjeOyjns0qnugwR -O /tmp/VOC_test.tar\n",
    "    !tar -xvf /tmp/VOC_test.tar\n",
    "    !mv VOCdevkit/VOC2012 VOC2012_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9103ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_size = 224\n",
    "pretrained_means = [0.485, 0.456, 0.406]\n",
    "pretrained_stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.RandomRotation(5),\n",
    "                           transforms.RandomHorizontalFlip(0.5),\n",
    "                           transforms.RandomCrop(pretrained_size, padding=10),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=pretrained_means,\n",
    "                                                std=pretrained_stds)\n",
    "                       ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=pretrained_means,\n",
    "                                                std=pretrained_stds)\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "904f0a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5717\n",
      "5823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008_000008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008_000015</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008_000019</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008_000023</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2008_000028</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11527</th>\n",
       "      <td>2011_003253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11529</th>\n",
       "      <td>2011_003255</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11531</th>\n",
       "      <td>2011_003259</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11537</th>\n",
       "      <td>2011_003274</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11539</th>\n",
       "      <td>2011_003276</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5717 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  label\n",
       "3      2008_000008      1\n",
       "5      2008_000015     13\n",
       "7      2008_000019      3\n",
       "9      2008_000023     13\n",
       "12     2008_000028      8\n",
       "...            ...    ...\n",
       "11527  2011_003253      1\n",
       "11529  2011_003255     15\n",
       "11531  2011_003259      9\n",
       "11537  2011_003274     19\n",
       "11539  2011_003276     10\n",
       "\n",
       "[5717 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "def load_dataset(c):\n",
    "    df = pd.read_csv(f\"{ROOT}/ImageSets/Main/{c}_trainval.txt\", delimiter=r\"\\s+\", header=None, names=('id', c))\n",
    "    return df\n",
    "\n",
    "classes = ['bicycle', 'horse', 'cat', 'dog', 'pottedplant', 'aeroplane', 'sofa', 'bus', 'car', 'chair', 'bird', 'boat', 'cow', 'bottle', 'diningtable', 'person', 'tvmonitor', 'sheep', 'motorbike', 'train']\n",
    "df = reduce(lambda df1,df2: pd.merge(df1,df2,on='id'), [load_dataset(c) for c in classes])\n",
    "df['label'] = df.apply(lambda row: row[classes].tolist().index(1), axis=1)\n",
    "\n",
    "with open(f\"{ROOT}/ImageSets/Main/train.txt\", 'r') as f:\n",
    "    _ = f.read().split('\\n')\n",
    "    df['train'] = df.apply(lambda row: row.values[0] in _, axis=1)\n",
    "train_data = df[df['train']][['id','label']]\n",
    "valid_data = df[df['train'] == False][['id','label']]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(valid_data))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "067c4184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008_000001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008_000004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008_000005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008_000006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008_000010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10986</th>\n",
       "      <td>2011_003264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10987</th>\n",
       "      <td>2011_003265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10988</th>\n",
       "      <td>2011_003266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10989</th>\n",
       "      <td>2011_003267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10990</th>\n",
       "      <td>2011_003268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10991 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  label\n",
       "0      2008_000001      0\n",
       "1      2008_000004      0\n",
       "2      2008_000005      0\n",
       "3      2008_000006      0\n",
       "4      2008_000010      0\n",
       "...            ...    ...\n",
       "10986  2011_003264      0\n",
       "10987  2011_003265      0\n",
       "10988  2011_003266      0\n",
       "10989  2011_003267      0\n",
       "10990  2011_003268      0\n",
       "\n",
       "[10991 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_dataset_test(c):\n",
    "    df = pd.read_csv(f\"{ROOT_test}/ImageSets/Main/{c}_test.txt\", delimiter=r\"\\s+\", header=None, names=('id', c))\n",
    "    return df\n",
    "\n",
    "df_test = reduce(lambda df1,df2: pd.merge(df1,df2,on='id'), [load_dataset_test(c) for c in classes])\n",
    "df_test['label'] = np.zeros(len(df_test), dtype=int)\n",
    "\n",
    "test_data = df_test[['id', 'label']]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8550e224",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VOCDataset' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m train_data \u001b[38;5;241m=\u001b[39m VOCDataset(train_data, train_transforms)\n\u001b[1;32m     21\u001b[0m valid_data \u001b[38;5;241m=\u001b[39m VOCDataset(valid_data, test_transforms)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mvalid_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m test_transforms\n\u001b[1;32m     23\u001b[0m test_data  \u001b[38;5;241m=\u001b[39m VOCDataset(test_data, test_transforms)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VOCDataset' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "class VOCDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.labels = data['label'].tolist()\n",
    "        self.image_paths = data['id'].tolist()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = f\"{ROOT}/JPEGImages/{self.data.iloc[idx].values[0]}.jpg\"\n",
    "        image = Image.open(image_filepath)\n",
    "        \n",
    "        label = self.data.iloc[idx].values[1]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "train_data = VOCDataset(train_data, train_transforms)\n",
    "valid_data = VOCDataset(valid_data, test_transforms)\n",
    "valid_data.dataset.transform = test_transforms\n",
    "test_data  = VOCDataset(test_data, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47f96395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min=image_min, max=image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image\n",
    "\n",
    "\n",
    "def plot_images(images, labels, classes, normalize=True):\n",
    "\n",
    "    n_images = len(images)\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "\n",
    "        image = images[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        ax.set_title(classes[labels[i]])\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMAGES = 25\n",
    "\n",
    "images, labels = zip(*[(image, label) for image, label in\n",
    "                       [train_data[i] for i in range(N_IMAGES)]])\n",
    "\n",
    "plot_images(images, labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9d839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator = data.DataLoader(train_data,\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(valid_data,\n",
    "                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "test_iterator = data.DataLoader(test_data,\n",
    "                                batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736df6ab",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45630cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_LR = 1e-7\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=START_LR)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model.features\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.classifier = model.classifier.to(device)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cccd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class LRFinder:\n",
    "    def __init__(self, model, optimizer, criterion, device):\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "\n",
    "        torch.save(model.state_dict(), 'init_params.pt')\n",
    "\n",
    "    def range_test(self, iterator, end_lr=10, num_iter=100,\n",
    "                   smooth_f=0.05, diverge_th=5):\n",
    "\n",
    "        lrs = []\n",
    "        losses = []\n",
    "        best_loss = float('inf')\n",
    "\n",
    "        lr_scheduler = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
    "\n",
    "        iterator = IteratorWrapper(iterator)\n",
    "\n",
    "        for iteration in tqdm(range(num_iter)):\n",
    "\n",
    "            loss = self._train_batch(iterator)\n",
    "\n",
    "            lrs.append(lr_scheduler.get_last_lr()[0])\n",
    "\n",
    "            # update lr\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            if iteration > 0:\n",
    "                loss = smooth_f * loss + (1 - smooth_f) * losses[-1]\n",
    "\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "\n",
    "            losses.append(loss)\n",
    "\n",
    "            if loss > diverge_th * best_loss:\n",
    "                print(\"Stopping early, the loss has diverged\")\n",
    "                break\n",
    "\n",
    "        # reset model to initial parameters\n",
    "        model.load_state_dict(torch.load('init_params.pt'))\n",
    "\n",
    "        return lrs, losses\n",
    "\n",
    "    def _train_batch(self, iterator):\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        x, y = iterator.get_batch()\n",
    "\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "\n",
    "        y_pred, _ = self.model(x)\n",
    "\n",
    "        loss = self.criterion(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "\n",
    "class ExponentialLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
    "        self.end_lr = end_lr\n",
    "        self.num_iter = num_iter\n",
    "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        curr_iter = self.last_epoch\n",
    "        r = curr_iter / self.num_iter\n",
    "        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in\n",
    "                self.base_lrs]\n",
    "\n",
    "\n",
    "class IteratorWrapper:\n",
    "    def __init__(self, iterator):\n",
    "        self.iterator = iterator\n",
    "        self._iterator = iter(iterator)\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            inputs, labels = next(self._iterator)\n",
    "        except StopIteration:\n",
    "            self._iterator = iter(self.iterator)\n",
    "            inputs, labels, *_ = next(self._iterator)\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def get_batch(self):\n",
    "        return next(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39c0f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "END_LR = 10\n",
    "NUM_ITER = 100\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device)\n",
    "lrs, losses = lr_finder.range_test(train_iterator, END_LR, NUM_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466258c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_finder(lrs, losses, skip_start=5, skip_end=5):\n",
    "\n",
    "    if skip_end == 0:\n",
    "        lrs = lrs[skip_start:]\n",
    "        losses = losses[skip_start:]\n",
    "    else:\n",
    "        lrs = lrs[skip_start:-skip_end]\n",
    "        losses = losses[skip_start:-skip_end]\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(lrs, losses)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Learning rate')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.grid(True, 'both', 'x')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955f0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lr_finder(lrs, losses, skip_start=10, skip_end=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e3f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOUND_LR = 5e-4\n",
    "\n",
    "params = [\n",
    "          {'params': model.features.parameters(), 'lr': FOUND_LR / 10},\n",
    "          {'params': model.classifier.parameters()}\n",
    "         ]\n",
    "\n",
    "optimizer = optim.Adam(params, lr=FOUND_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f9b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred, _ = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6007571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82321b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40836c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "\n",
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "universal",
   "language": "python",
   "name": "universal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
